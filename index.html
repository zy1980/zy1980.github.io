<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Science, Engineering, Life</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="Science, Engineering, Life">
<meta property="og:url" content="http://blog.chihyang.com/index.html">
<meta property="og:site_name" content="Science, Engineering, Life">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Science, Engineering, Life">
<meta name="twitter:description">
  
    <link rel="alternative" href="/atom.xml" title="Science, Engineering, Life" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="http://fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Science, Engineering, Life</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="https://www.linkedin.com/in/zhiyang">About Me</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="http://chihyangscience.github.io">Old Stuff</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="q" value="site:http://blog.chihyang.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-RBM-for-Real-valued-data" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/05/10/RBM-for-Real-valued-data/" class="article-date">
  <time datetime="2015-05-10T05:00:40.000Z" itemprop="datePublished">2015-05-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/05/10/RBM-for-Real-valued-data/">RBM for Real-valued data</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>RBM can be generalized to real value input, suppose input unit $v \in R^D$ and stochastic hidden unit h is still the binary unit.</p>
<p>We treat the input v as Gaussian random variables, the energy of RBM defined as:<br>$$<br>E(v,h,\theta)=\sum^D_{i=1}\frac{(v_i-b_i)^2}{2\sigma_i^2}-\sum^D_{i=1}\sum^F_{j=1}w_{ij}h_j\frac{v_i}{\sigma_i}-\sum^F_{j=1}a_jh_j<br>$$</p>
<p>the conditional distribution then changed to:<br>$$<br>p(v_i=x|h)=\frac{1}{(2\pi\sigma_i)^{1/2}}exp(-\frac{(x-b_i-\sigma_i\sum_jh_jw_{ij})^2}{2\sigma_i^2}) \\<br>p(h_j=1|v)=\sigma(b_j+\sum_iw_{ij}\frac{v_i}{\sigma_i})<br>$$</p>
<p>to train it, the derivative of the log-likelihood with respect to w:<br>$$<br>\frac{\partial logp(v,\theta)}{\partial w_{ij}}=&lt;\frac{1}{\sigma_i}v_ih_j&gt;_{data}-&lt;\frac{1}{\sigma_i}v_ih_j&gt;_{model}<br>$$</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://blog.chihyang.com/2015/05/10/RBM-for-Real-valued-data/" data-id="ci9hzza8z0003lgs6xg893yxj" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-RBM-for-Collaborative-Filtering" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/05/06/RBM-for-Collaborative-Filtering/" class="article-date">
  <time datetime="2015-05-06T07:31:02.000Z" itemprop="datePublished">2015-05-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/05/06/RBM-for-Collaborative-Filtering/">RBM for Collaborative Filtering</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>RBM is the best single model for collaborative filtering, suppose we have M movies, N users, and integer rating values from 1 to K. To use RBM model, use a different RBM for each user, every RBM has the same number of hidden units, but an RBM only has visible softmax units for the movies rated by that user, so an RBM has few connections if that user rated few movies, to simply the model, assume weights and biases are tied together, so if two users have rated the same movie, their two RBM’s must use the same weights between the softmax visible unit for that movie and the hidden units, an suppose a user rated m movies, let V be a K × m observed binary indicator matrix with $v_{i}^k = 1$ if the user rated movie i as k and 0 otherwise. also let $h_j$, j = 1,…,F. So this is a softmax RBM, to make prediction, need to evaluate:<br>$$<br>p(v_q^k=1|V)=\frac{p(v_q^k,V)}{p(V)} \sim \sum_h exp(-E(v_q^k,V,h))\\<br>\sim exp(v_q^kb_q^k)\prod^F_{j=1}(1+exp(\sum_{il}v_i^lw_{ij}^l+v_q^kw_{qj}^k+b_j))<br>$$</p>
<p>after train the model, pick the rating k with the maximum probability.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://blog.chihyang.com/2015/05/06/RBM-for-Collaborative-Filtering/" data-id="ci9hzza9i0005lgs6zcyx8iey" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-restricted-Boltzmann-machine-on-document-classification" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/05/03/restricted-Boltzmann-machine-on-document-classification/" class="article-date">
  <time datetime="2015-05-03T07:40:19.000Z" itemprop="datePublished">2015-05-03</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/05/03/restricted-Boltzmann-machine-on-document-classification/">restricted Boltzmann machine on document classification</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Restricted Boltzmann machine can be used for document classification as kind of latent factor model, and it is a unsupervised learning model.</p>
<p>Suppose K is the dictionary size and D is the document size, each word in document is a input of RBM v, F is number of document topic, each topic is a hidden binary unit h,so we are interested to get $p(H_i=1|V)$ which is the posterior probability of the topic,  V is a K × D observed binary matrix with $v_i^k = 1$ if visible unit i takes on kth value, it is a softmax RBM:<br>$$<br>p(V,h)=\frac{1}{Z}e^{-E(V,h)} \\<br>E(V,h)=-\sum^D_{i=1}\sum^F_{j=1}\sum^K_{k=1}w^k_{ij}h_jv^k_i-\sum^D_{i=1}\sum^K_{k=1}v^k_ib^k_i-\sum^F_{j=1}h_ja_j \\<br>$$</p>
<p>to make it scale with variable document size, change the hidden unit term, instead use energy:<br>$$<br>E(V,h)=-\sum^D_{i=1}\sum^F_{j=1}\sum^K_{k=1}w^k_{ij}h_jv^k_i-\sum^D_{i=1}\sum^K_{k=1}v^k_ib^k_i-D\sum^F_{j=1}h_ja_j<br>$$</p>
<p>because the document size is variable, so for each document define a RBM, to simplify the model, assume all of these softmax units can share the same set of weights, connecting them to binary hidden units and ignore the word order, so $w^k_{ij}$ independent of work input, $w^k_{ij}=w^k_j$, define $\bar{v}^k=\sum^D_{i=1}v^k_i$ to be the count of the k-th word in the document, energy can be written:<br>$$<br>E(V,h)=-\sum^F_{j=1}\sum^K_{k=1}w^k_{j}h_j\bar{v}^k-\sum^K_{k=1}\bar{v}^kb^k_i-D\sum^F_{j=1}h_ja_j<br>$$</p>
<p>conditional distribution changed to:<br>$$<br>p(h_j=1|V)=\sigma(Da_j+\sum^K_{k=1}w^k_j\bar{v}^k)<br>$$</p>
<p>The training process is same as before which use Contrastive Divergence:<br>$$<br>\delta w^k_j=\alpha ([\bar{v}^k h_j]_{data}−[\bar{v}^kh_j]_T)<br>$$</p>
<p>After train the model, for each document V, we can evaluate $p(h_j|V)$, classify it to topic j which having latest posterior probability.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://blog.chihyang.com/2015/05/03/restricted-Boltzmann-machine-on-document-classification/" data-id="ci9hzza6t0000lgs6h1lyen03" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-ALS-collaborative-filtering-for-implicit-feedback-data" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/05/02/ALS-collaborative-filtering-for-implicit-feedback-data/" class="article-date">
  <time datetime="2015-05-02T07:22:56.000Z" itemprop="datePublished">2015-05-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/05/02/ALS-collaborative-filtering-for-implicit-feedback-data/">ALS collaborative filtering for implicit feedback data</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Previous post talk about ALS collaborative filtering for explict feedback data, the rating gives user’s preference on items, but in many situations, the rating is not available directly, instead we can get some implict feedback data, e.g. $r_{ui}$ express how frequently a user is buying a certain item, how much time the user view a web page. For these kind of data, there is a variant ALS collaborative filtering solution for it.</p>
<p>Normally the numerical values of implicit feedback describe the frequency of actions, it express confidence how user like or dislike the item. Introduce binary variables $p_{ui}$, indicates the preference of user u to item i, defined as:<br>$$<br>p_{ui}=1 \text{ if } r_{ui}&gt;0, \text{ else } =0<br>$$</p>
<p>to express the confidence of the preference, introdcue another variable:<br>$$<br>c_{ui}=1+\alpha r_{ui}<br>$$</p>
<p>$\alpha$ controlled by experiment, as observe more evidence for positive preference, confidence in $p_{ui} = 1$ increases accordingly. We still employ the latent factor model, assume there is user factor $x_u$, item factor $y_i$, their inner product determine the perference, that is:<br>$$<br>p_{ui}=x^T_uy_i<br>$$</p>
<p>here user and item factor should be common latent factor, because $p_{ui}$ is independent of scale, so it make sense. The cost function will be minimized is:<br>$$<br>\sum_{u,i}c_{ui}(p_{ui}-x^T_uy_i)^2+\lambda(\sum_u|x_u|^2+\sum_i|y_i|^2)<br>$$</p>
<p>which weighted by its confidence. suppose $y_i$ is i-th row of nxf matrix Y, $x_u$ is u-th row of mxf matrix X, and for each user introduce diagonal nxn matrix $C^u$ for $C^u_{ii}=c_{ui}$,and vector $p(u) \in R^n$ contains all the preferences by u(the $p_{ui}$ values), derivative w.r.t $x_u$, get:<br>$$<br>-\sum_ic_{ui}(p_{ui}-x^T_uy_i)y_i+\lambda x_u=0 \\<br>=&gt; x_u=(\sum_i c_{ui}y_iy_i^T+\lambda)^{-1}\sum_ic_{ui}p_{ui}y_i \\<br>=&gt; x_u=(Y^TC^uY+\lambda I)^{-1}Y^TC^up(u)<br>$$</p>
<p>same process get:<br>$$<br>y_i=(X^TC^iX+\lambda I)^{-1}X^TC^ip(i)<br>$$</p>
<p>here p(i) is all the preferences for i, $C^i$ is diagonal m×m matrix C where $C^i_{uu} = c_{ui}$, to evaluate $Y^TC^uY$, note: $Y^TC^uY=Y^TY+Y^T(C^u-I)Y$, there are only small fraction of non-zero elements, this will speed up the calculation.</p>
<p>When make recommendation, the inner product generally will not be 1 or 0, so recommend to user u the K items with the top K largest values of $p_{ui}$</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://blog.chihyang.com/2015/05/02/ALS-collaborative-filtering-for-implicit-feedback-data/" data-id="ci9hzza9p000algs6vf3ix29s" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Old-Blogs-here" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/05/01/Old-Blogs-here/" class="article-date">
  <time datetime="2015-05-01T10:56:14.000Z" itemprop="datePublished">2015-05-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/05/01/Old-Blogs-here/">Old Blogs here</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Some old blogs here:<br><a href="http://chihyangscience.github.io" target="_blank" rel="external">http://chihyangscience.github.io</a><br><a href="http://blog.linkweb.me" target="_blank" rel="external">http://blog.linkweb.me</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://blog.chihyang.com/2015/05/01/Old-Blogs-here/" data-id="ci9hzza9l0007lgs6snaeuwe1" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/life/">life</a></li></ul>

    </footer>
  </div>
  
</article>


  
  
</section>
        
          <aside id="sidebar">
  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/life/">life</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/">machine learning</a><span class="tag-list-count">4</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/life/" style="font-size: 10px;">life</a><a href="/tags/machine-learning/" style="font-size: 20px;">machine learning</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">May 2015</a><span class="archive-list-count">5</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2015/05/10/RBM-for-Real-valued-data/">RBM for Real-valued data</a>
          </li>
        
          <li>
            <a href="/2015/05/06/RBM-for-Collaborative-Filtering/">RBM for Collaborative Filtering</a>
          </li>
        
          <li>
            <a href="/2015/05/03/restricted-Boltzmann-machine-on-document-classification/">restricted Boltzmann machine on document classification</a>
          </li>
        
          <li>
            <a href="/2015/05/02/ALS-collaborative-filtering-for-implicit-feedback-data/">ALS collaborative filtering for implicit feedback data</a>
          </li>
        
          <li>
            <a href="/2015/05/01/Old-Blogs-here/">Old Blogs here</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2015 chih.yang@outlook.com<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="https://www.linkedin.com/in/zhiyang" class="mobile-nav-link">About Me</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="http://chihyangscience.github.io" class="mobile-nav-link">Old Stuff</a>
  
</nav>
    

<script src="//ajax.useso.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>

<script type="text/x-mathjax-config"> 
MathJax.Hub.Config({ 
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]} 
}); 
</script>
<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

  </div>
</body>
</html>